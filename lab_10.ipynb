{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAT 207 Lab 10: Train/Test Classification ROC and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due: Wednesday, November 20, 23:59:59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaewon Kim jaewonk3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab consists of 2 main parts. You may add as many cells as you need in order to do the exercises. To add cells use the \"Insert\" tab from the menu bar above and select \"insert cell above\" or \"insert cell below\". \n",
    "\n",
    "Please use Markdown cells above or below your code cells to explain your results. Make sure graders know that you understand what your code is doing.\n",
    "\n",
    "**Hint: all of the problems build on the class notes, so the notes are the first place to go for related examples and discussion.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code below generates training data and test data for you to analyze in this lab. Run the code and then work on the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to generate labeled data for classification\n",
    "n = 500       # sample size\n",
    "nX = 10       # number of explanatory features to generate\n",
    "spread = 10   # standard deviation within clusters\n",
    "# Generate labeled data:\n",
    "X, y = make_blobs(n_samples=n, centers=2, n_features=nX, \n",
    "                  random_state=1, cluster_std=spread)\n",
    "# Create variable names for X features\n",
    "Xnames = []\n",
    "for i in range(nX):\n",
    "    list.append(Xnames, 'X'+str(i))\n",
    "# load X into data frame\n",
    "df = pd.DataFrame(X, columns=Xnames)\n",
    "# Add y to the data frame\n",
    "df['y'] = y\n",
    "# split the data frame into training data (traindf) and testing data (testdf)\n",
    "traindf, testdf = train_test_split(df, test_size=0.20, random_state=12347)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-6.435368</td>\n",
       "      <td>4.666490</td>\n",
       "      <td>-23.484677</td>\n",
       "      <td>9.072007</td>\n",
       "      <td>-10.691003</td>\n",
       "      <td>-23.004793</td>\n",
       "      <td>-12.199409</td>\n",
       "      <td>-26.137865</td>\n",
       "      <td>-2.382822</td>\n",
       "      <td>1.901212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1.845900</td>\n",
       "      <td>-8.716344</td>\n",
       "      <td>-10.384668</td>\n",
       "      <td>-20.111072</td>\n",
       "      <td>4.149295</td>\n",
       "      <td>-4.064223</td>\n",
       "      <td>-6.520965</td>\n",
       "      <td>-10.840402</td>\n",
       "      <td>10.672909</td>\n",
       "      <td>20.447352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>-4.989501</td>\n",
       "      <td>-7.946010</td>\n",
       "      <td>-19.846998</td>\n",
       "      <td>-1.478810</td>\n",
       "      <td>-1.697234</td>\n",
       "      <td>4.612270</td>\n",
       "      <td>8.939545</td>\n",
       "      <td>5.623697</td>\n",
       "      <td>-1.725363</td>\n",
       "      <td>3.425534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>-0.681983</td>\n",
       "      <td>19.252675</td>\n",
       "      <td>-4.042774</td>\n",
       "      <td>16.990513</td>\n",
       "      <td>2.792178</td>\n",
       "      <td>4.779663</td>\n",
       "      <td>9.518555</td>\n",
       "      <td>-0.937090</td>\n",
       "      <td>-4.949669</td>\n",
       "      <td>-21.225907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-13.311740</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>-9.117352</td>\n",
       "      <td>-11.370951</td>\n",
       "      <td>-17.790135</td>\n",
       "      <td>-5.252814</td>\n",
       "      <td>-13.893143</td>\n",
       "      <td>-12.684104</td>\n",
       "      <td>-5.056183</td>\n",
       "      <td>3.631249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            X0         X1         X2         X3         X4         X5  \\\n",
       "63   -6.435368   4.666490 -23.484677   9.072007 -10.691003 -23.004793   \n",
       "143   1.845900  -8.716344 -10.384668 -20.111072   4.149295  -4.064223   \n",
       "365  -4.989501  -7.946010 -19.846998  -1.478810  -1.697234   4.612270   \n",
       "487  -0.681983  19.252675  -4.042774  16.990513   2.792178   4.779663   \n",
       "148 -13.311740   0.152300  -9.117352 -11.370951 -17.790135  -5.252814   \n",
       "\n",
       "            X6         X7         X8         X9  y  \n",
       "63  -12.199409 -26.137865  -2.382822   1.901212  0  \n",
       "143  -6.520965 -10.840402  10.672909  20.447352  0  \n",
       "365   8.939545   5.623697  -1.725363   3.425534  0  \n",
       "487   9.518555  -0.937090  -4.949669 -21.225907  1  \n",
       "148 -13.893143 -12.684104  -5.056183   3.631249  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(traindf.shape, traindf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>14.485931</td>\n",
       "      <td>9.929339</td>\n",
       "      <td>-29.479604</td>\n",
       "      <td>-1.435526</td>\n",
       "      <td>-20.052591</td>\n",
       "      <td>-4.367626</td>\n",
       "      <td>0.906620</td>\n",
       "      <td>-5.978525</td>\n",
       "      <td>5.057209</td>\n",
       "      <td>5.049409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>7.907335</td>\n",
       "      <td>3.590790</td>\n",
       "      <td>5.294766</td>\n",
       "      <td>2.911478</td>\n",
       "      <td>10.106005</td>\n",
       "      <td>-16.195998</td>\n",
       "      <td>-3.272259</td>\n",
       "      <td>-7.384742</td>\n",
       "      <td>5.994483</td>\n",
       "      <td>-1.419187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.589293</td>\n",
       "      <td>0.841541</td>\n",
       "      <td>-10.375409</td>\n",
       "      <td>9.685736</td>\n",
       "      <td>-13.426361</td>\n",
       "      <td>10.472702</td>\n",
       "      <td>-0.999738</td>\n",
       "      <td>-1.099517</td>\n",
       "      <td>-2.301751</td>\n",
       "      <td>-14.713002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>-22.394710</td>\n",
       "      <td>27.180549</td>\n",
       "      <td>21.150294</td>\n",
       "      <td>1.048733</td>\n",
       "      <td>-9.949342</td>\n",
       "      <td>4.207245</td>\n",
       "      <td>2.025323</td>\n",
       "      <td>7.091138</td>\n",
       "      <td>-23.728960</td>\n",
       "      <td>-16.342430</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-0.797608</td>\n",
       "      <td>8.652012</td>\n",
       "      <td>-10.150453</td>\n",
       "      <td>15.527657</td>\n",
       "      <td>-10.152889</td>\n",
       "      <td>-3.318075</td>\n",
       "      <td>-0.709750</td>\n",
       "      <td>-13.393106</td>\n",
       "      <td>-25.551252</td>\n",
       "      <td>-2.647719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            X0         X1         X2         X3         X4         X5  \\\n",
       "470  14.485931   9.929339 -29.479604  -1.435526 -20.052591  -4.367626   \n",
       "144   7.907335   3.590790   5.294766   2.911478  10.106005 -16.195998   \n",
       "22    0.589293   0.841541 -10.375409   9.685736 -13.426361  10.472702   \n",
       "494 -22.394710  27.180549  21.150294   1.048733  -9.949342   4.207245   \n",
       "106  -0.797608   8.652012 -10.150453  15.527657 -10.152889  -3.318075   \n",
       "\n",
       "           X6         X7         X8         X9  y  \n",
       "470  0.906620  -5.978525   5.057209   5.049409  1  \n",
       "144 -3.272259  -7.384742   5.994483  -1.419187  0  \n",
       "22  -0.999738  -1.099517  -2.301751 -14.713002  1  \n",
       "494  2.025323   7.091138 -23.728960 -16.342430  1  \n",
       "106 -0.709750 -13.393106 -25.551252  -2.647719  1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(testdf.shape, testdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Use the training data for model building (16 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) (2 pts) Using the training data only, fit a logistic regression model that includes all 10 variables. Show the model summary and identify which if any variables have coefficients that are significant at level alpha = 0.05.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.377564\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>  <td>   400</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   389</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    10</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 19 Nov 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.4553</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>20:47:08</td>     <th>  Log-Likelihood:    </th> <td> -151.03</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -277.25</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.652e-48</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.1161</td> <td>    0.260</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.625</td> <td>    0.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X0</th>        <td>   -0.0081</td> <td>    0.014</td> <td>   -0.567</td> <td> 0.570</td> <td>   -0.036</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>        <td>   -0.0021</td> <td>    0.016</td> <td>   -0.135</td> <td> 0.892</td> <td>   -0.033</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>        <td>    0.0257</td> <td>    0.015</td> <td>    1.694</td> <td> 0.090</td> <td>   -0.004</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>        <td>    0.1061</td> <td>    0.016</td> <td>    6.437</td> <td> 0.000</td> <td>    0.074</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>        <td>   -0.0208</td> <td>    0.015</td> <td>   -1.413</td> <td> 0.158</td> <td>   -0.050</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X5</th>        <td>    0.1124</td> <td>    0.016</td> <td>    7.020</td> <td> 0.000</td> <td>    0.081</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X6</th>        <td>    0.0426</td> <td>    0.015</td> <td>    2.801</td> <td> 0.005</td> <td>    0.013</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X7</th>        <td>    0.0449</td> <td>    0.016</td> <td>    2.888</td> <td> 0.004</td> <td>    0.014</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X8</th>        <td>   -0.0563</td> <td>    0.015</td> <td>   -3.793</td> <td> 0.000</td> <td>   -0.085</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X9</th>        <td>   -0.0639</td> <td>    0.015</td> <td>   -4.186</td> <td> 0.000</td> <td>   -0.094</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  400\n",
       "Model:                          Logit   Df Residuals:                      389\n",
       "Method:                           MLE   Df Model:                           10\n",
       "Date:                Tue, 19 Nov 2019   Pseudo R-squ.:                  0.4553\n",
       "Time:                        20:47:08   Log-Likelihood:                -151.03\n",
       "converged:                       True   LL-Null:                       -277.25\n",
       "                                        LLR p-value:                 1.652e-48\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.1161      0.260     -0.447      0.655      -0.625       0.393\n",
       "X0            -0.0081      0.014     -0.567      0.570      -0.036       0.020\n",
       "X1            -0.0021      0.016     -0.135      0.892      -0.033       0.029\n",
       "X2             0.0257      0.015      1.694      0.090      -0.004       0.056\n",
       "X3             0.1061      0.016      6.437      0.000       0.074       0.138\n",
       "X4            -0.0208      0.015     -1.413      0.158      -0.050       0.008\n",
       "X5             0.1124      0.016      7.020      0.000       0.081       0.144\n",
       "X6             0.0426      0.015      2.801      0.005       0.013       0.072\n",
       "X7             0.0449      0.016      2.888      0.004       0.014       0.075\n",
       "X8            -0.0563      0.015     -3.793      0.000      -0.085      -0.027\n",
       "X9            -0.0639      0.015     -4.186      0.000      -0.094      -0.034\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "mod = smf.logit(formula = 'y ~ X0 + X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9', data = traindf).fit()\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AIC criterion for model selection:** The AIC criterion is one method for evaluating a fitted model. It is a function of negative log-likelihood (a measure of model fit), and number of parameters (complexity of the model). It aims to trade off model fit and model complexity to avoid 'overfitting' and enhance generalizability. When used as a model selection criterion, models with lower AIC are considered more generalizable than models with higher AIC. \n",
    "\n",
    "When using the statsmodels.formula.api logit method for fitting the model the AIC crieterion can be obtained from the fitted model using the .aic extension (e.g. model1.aic). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) (1 pt) Display the AIC value for the model in a).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324.05131651164226"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) (8 pts) Using the training data only, and by fitting a bunch of different models with different subsets of the variables included, try to find a simplified model than uses less than 10 variables and satisfies the following conditions:**\n",
    "\n",
    "+ **All variables included in the model (except possibly the intercept) have coefficient p-values below 0.05;**\n",
    "\n",
    "+ **Among such models, the AIC is as small as possible.**\n",
    "\n",
    "+ **Include the intercept in all models.**\n",
    "\n",
    "**One strategy is to sequentially drop variables that are not significant and fit the resulting simplified model, checking for consistency with the conditions. In addition to your final model, make a list of the intermediate models you tried and their AIC values. identify the models by which variables are included, and indicate which variables were signficant in the model. You might list them in the following form, for example:**\n",
    "\n",
    "| Model Variables | Least Significant variable | AIC |\n",
    "| --- | --- | --- |\n",
    "| X0, X1, ..., X9 | X5 (p=0.95) | etc. |\n",
    "| etc. | etc. | etc. |\n",
    "| X0, X1, X4 | X4 (p=0.041) | 68.33 |\n",
    "| etc. | etc. | etc. |\n",
    "\n",
    "**Another useful bit of information is that you can access the p-values from the fitted model using the .pvalues extension, e.g., model1.pvalues. That way you can avoid having to display the model summary for each model you try.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.383951\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Intercept    5.011499e-01\n",
       "X3           7.200283e-11\n",
       "X5           5.035771e-13\n",
       "X6           4.881818e-03\n",
       "X7           3.898269e-03\n",
       "X8           1.616698e-04\n",
       "X9           1.056252e-05\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2 = smf.logit(formula = 'y ~ X3 + X5 + X6 + X7 + X8 + X9', data = traindf).fit()\n",
    "mod2.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321.1607725023934"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smf.logit(formula = 'y ~ X0 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9', data = traindf), X0, aic = 322.0696495576599"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smf.logit(formula = 'y ~ X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9', data = traindf), X4 , aic = 320.3901011064893"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smf.logit(formula = 'y ~ X2 + X3 + X5 + X6 + X7 + X8 + X9', data = traindf), X2, aic = 320.3727751111385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smf.logit(formula = 'y ~ X3 + X5 + X6 + X7 + X8 + X9', data = traindf), X6, aic = \n",
    "321.1607725023934"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) (1 pts) Show the model summary for the final model you selected. Explain briefly why it is the best model you found.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>  <td>   400</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   393</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 19 Nov 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.4461</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>20:47:08</td>     <th>  Log-Likelihood:    </th> <td> -153.58</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -277.25</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.513e-50</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.1165</td> <td>    0.173</td> <td>   -0.673</td> <td> 0.501</td> <td>   -0.456</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>        <td>    0.1039</td> <td>    0.016</td> <td>    6.516</td> <td> 0.000</td> <td>    0.073</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X5</th>        <td>    0.1145</td> <td>    0.016</td> <td>    7.224</td> <td> 0.000</td> <td>    0.083</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X6</th>        <td>    0.0422</td> <td>    0.015</td> <td>    2.815</td> <td> 0.005</td> <td>    0.013</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X7</th>        <td>    0.0440</td> <td>    0.015</td> <td>    2.886</td> <td> 0.004</td> <td>    0.014</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X8</th>        <td>   -0.0544</td> <td>    0.014</td> <td>   -3.772</td> <td> 0.000</td> <td>   -0.083</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X9</th>        <td>   -0.0666</td> <td>    0.015</td> <td>   -4.405</td> <td> 0.000</td> <td>   -0.096</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  400\n",
       "Model:                          Logit   Df Residuals:                      393\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Tue, 19 Nov 2019   Pseudo R-squ.:                  0.4461\n",
       "Time:                        20:47:08   Log-Likelihood:                -153.58\n",
       "converged:                       True   LL-Null:                       -277.25\n",
       "                                        LLR p-value:                 1.513e-50\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.1165      0.173     -0.673      0.501      -0.456       0.223\n",
       "X3             0.1039      0.016      6.516      0.000       0.073       0.135\n",
       "X5             0.1145      0.016      7.224      0.000       0.083       0.146\n",
       "X6             0.0422      0.015      2.815      0.005       0.013       0.072\n",
       "X7             0.0440      0.015      2.886      0.004       0.014       0.074\n",
       "X8            -0.0544      0.014     -3.772      0.000      -0.083      -0.026\n",
       "X9            -0.0666      0.015     -4.405      0.000      -0.096      -0.037\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has the lowest AIC with all of the coefficients are significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) (4 pts) Treating your final model as a classifier, compute and display the 'naive' estimates of sensitivity and specificity using the training data. Use the classification threshold:**\n",
    "\n",
    "+ **Classify as 1 if the predictive probability (model fitted value) is 0.5 or greater,**\n",
    "\n",
    "+ **Classify as 0 if the predictive probability is less than 0.5.**\n",
    "\n",
    "**A function to compute sensitivity and specificity was included in the class notes. You may include it in your code if helpful.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "phat = mod2.predict(exog = traindf[['X3', 'X5', 'X6', 'X7', 'X8', 'X9']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def senspec(y, score, thresh):\n",
    "    yhat = 1*(score >= thresh)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true = y, y_pred = yhat).ravel()\n",
    "    sens = tp / (fn + tp)\n",
    "    spec = tn / (fp + tn)\n",
    "    return {'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp, 'sens': sens, 'spec': spec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tn': 159,\n",
       " 'fp': 40,\n",
       " 'fn': 33,\n",
       " 'tp': 168,\n",
       " 'sens': 0.835820895522388,\n",
       " 'spec': 0.7989949748743719}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senspec(traindf['y'], phat, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Use the test data for model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) (4 pts) Using the model from Part 1d) as a classifier, with the same threshold as in Part 1e), use the test data to compute sensitivity and specificity. This will require classifying the test data and then computing the true positive, false negatives and so on. Display the code and results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phat2 = mod2.predict(exog = testdf[['X3', 'X5', 'X6', 'X7', 'X8', 'X9']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tn': 42,\n",
       " 'fp': 9,\n",
       " 'fn': 8,\n",
       " 'tp': 41,\n",
       " 'sens': 0.8367346938775511,\n",
       " 'spec': 0.8235294117647058}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senspec(testdf['y'], phat2, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) (4 pts) Using the test data only for evaluation, compute and display the ROC curve for the model in Part 1d) that you developed from the training data. You may use any functions developed in the class notes for this purpose if helpful.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, auc, lw = 2):\n",
    "    plt.plot(fpr, tpr, color = 'darkorange', lw = lw, label = 'ROC curve (area = '+str(round(auc, 3))+')')\n",
    "    plt.plot([0,1], [0,1], color = 'navy', lw = lw, linestyle = '--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcjeX7wPHPNTMY+65C9t1gZCgpyZayRBQl4iuiREqL4iflW9JiCSGkvi30FVERCSlf+x6SscQo2QZjzD7X749znMaY5Qxz5syZud6v13k5z3Pu8zzXc5w513Pf9/Pct6gqxhhjDICftwMwxhiTfVhSMMYY42JJwRhjjIslBWOMMS6WFIwxxrhYUjDGGONiScEYY4yLJQWTo4jIERGJEpGLInJCROaKSKFkZW4XkVUiEiEi50XkGxGpk6xMERGZKCJHndsKdS6XSmW/IiJDRORXEYkUkTAR+a+I1PPk8RqT2SwpmJyoo6oWAoKBhsCIyy+ISFNgBbAYKAtUBnYC60SkirNMXuBHoC7QDigC3A6cAZqkss9JwFBgCFACqAF8DbTPaPAiEpDR9xiTWcTuaDY5iYgcAR5X1ZXO5fFAXVVt71z+Gditqk8me98y4JSq9haRx4F/A1VV9aIb+6wO/AY0VdVNqZRZA3yqqrOcy32ccd7hXFZgMPAMEAAsBy6q6vAk21gM/KSq74lIWeB9oDlwEZigqpPd+IiMSZPVFEyOJSLlgXuBUOdyARxn/P9NofiXQBvn89bA9+4kBKdWQFhqCSEDOgO3AnWAz4HuIiIAIlIcaAvMExE/4BscNZxyzv0/IyL3XOf+jbGkYHKkr0UkAjgGnARGO9eXwPGd/yuF9/wFXO4vKJlKmdRktHxq3lTVs6oaBfwMKHCn87VuwHpV/RNoDJRW1ddUNVZVDwEfAj0yIQaTy1lSMDlRZ1UtDLQAavHPj304kAjclMJ7bgJOO5+fSaVMajJaPjXHLj9RR7vuPOBh56pHgM+czysCZUXk3OUH8DJwQybEYHI5Swomx1LVn4C5wDvO5UhgPfBgCsUfwtG5DLASuEdECrq5qx+B8iISkkaZSKBAkuUbUwo52fIXQDcRqYijWekr5/pjwGFVLZbkUVhV73MzXmNSZUnB5HQTgTYiEuxcfgl4zHn5aGERKS4iY4GmwBhnmf/g+OH9SkRqiYifiJQUkZdF5KofXlU9AEwDvhCRFiKSV0QCRaSHiLzkLLYDeEBECohINaBfeoGr6nbgFDALWK6q55wvbQIuiMiLIpJfRPxFJEhEGl/LB2RMUpYUTI6mqqeAT4BRzuVfgHuAB3D0A/yB47LVO5w/7qhqDI7O5t+AH4ALOH6ISwEbU9nVEGAKMBU4BxwEuuDoEAaYAMQCfwMf809TUHq+cMbyeZJjSgA64rjk9jCOZq9ZQFE3t2lMquySVGOMMS5WUzDGGONiScEYY4yLJQVjjDEulhSMMca4+NzAW6VKldJKlSp5OwxjjPEpW7duPa2qpdMr53NJoVKlSmzZssXbYRhjjE8RkT/cKWfNR8YYY1wsKRhjjHGxpGCMMcbFkoIxxhgXSwrGGGNcPJYURGSOiJwUkV9TeV1EZLJzQvRdInKLp2IxxhjjHk/WFObimPQ8NfcC1Z2PAcAHHozFGGOMGzx2n4KqrhWRSmkUuR/4xDnD1AYRKSYiN6lqZkxraIzDwvZweKm3ozDmumw6Wo7AgHjql/0bnvPsyNbe7FMoR5LpB4Ew57qriMgAEdkiIltOnTqVJcGZHMISgvFhqvDCt21o+n4/HpvXmbgEz/9ke/OOZklhXYopUFVnAjMBQkJCbAIIk3EePrsyxhME4OQPsHY9bR/tSsKQKeTx8D69mRTCgJuTLJcH/vRSLMYYky2cOxfNoUPh3HLLTQCMGdOCHj2CXMue5s2ksAQYLCLzcExKft76E0y6rI/A5GCLF//GoEHf4ecn7NnzJEWLBpI/f54sSwjgwaQgIl8ALYBSIhIGjAZHzUdVpwNLgfuAUOAS0NdTsZgc5FoSQuX7Mj8OYzLRyZORDBmyjPnz9wBw223lOXcumqJFA7M8Fk9effRwOq8r8JSn9m9yOOsjMDmAqvLZZ7sZOvR7zp6NokCBPLzxRksGD26Cv793rgPyuaGzjTEmpxg06DtmzNgKQOvWVZg5swOVKxf3akyWFHIba5M3Jtvo3LkW8+fv4d1329K3bzAiKV2UmbUsKeQ2OSEhWB+B8VEHDpzhxx8PM3BgCADt2lXjyJGhXuk7SI0lhdzK2uSNyTLx8Ym89956Ro9eQ0xMPMHBN3LbbeUBslVCAEsKxhjjUTt3nqBfvyVs3eq44r537wZUr17Cy1GlzpKCMcZ4QExMPGPHrmXcuHXExydSoUJRZszoQLt21bwdWposKRhjjAeMGPEjEyZsAOCppxrz5putKFw4n5ejSp8lBWOM8YAXXmjG+vVhjB/fmjvvrOjtcNxmM68ZY0wm+OGHg3Tt+iXx8YkA3HhjIf73v3/5VEIASwrGGHNdwsOj6NdvMW3bfsrChfv46KPtrteyw30HGWXNR8YYc40WLdrHk08u5cSJi+TL58/o0XfRp0+wt8O6LpYUjDEmg06cuMjTTy9jwYK9ANx++83Mnt2JWrVKeTmy62dJwRhjMmjx4t9YsGAvBQvmYdy41jz5ZGP8/HyvqSgllhSMMcYN0dHxBAY6fjL792/EoUPhDBrUmEqVink5ssxlHc3GGJOGxERlypRNVK48iT/+OAeAn5/w1lttclxCAEsKxhiTqv37T9O8+Uc8/fQyTpy4yBdf/OrtkDzOmo+MMSaZuLgE3nnnf4wZ8xMxMQnccENBpk1rzwMP1PZ2aB5nSSGnsnkTjLkmv/56kt69F7F9+wkA+vYN5t1321K8eH4vR5Y1LCnkVGklBJuPwJhUJSYqu3efpGLFosyc2ZG2bat6O6QsZUkhp7N5E4xJ1549J6lTpzQiQv36N7B4cQ+aN69IoUJ5vR1alrOOZmNMrhUREcPgwUsJCvqAr77a51p/333Vc2VCAKspGGNyqeXLQxkw4FuOHj1PQIAfR46c83ZI2YIlBWNMrnL2bBTDhi3nk092AnDLLTcxe3YngoNv9HJk2YMlBWNMrrFjxwnatfuUv/+OJF8+f8aMacFzz91OQIC1pF9mScEYk2vUqFGSQoXyUqNGSWbN6kSNGiW9HVK2Y0nBGJNjqSqff76bjh1rUqRIPgoUyMOaNX0oW7ZwjhnALrNZUshu7KYzYzLFkSPnGDDgG3744RCDBoUwbVp7AMqXL+LlyLI3SwrZTWYmBLtJzeRCCQmJTJu2mREjfiQyMo4SJfJz++03ezssn2FJIbuym86MybB9+07Rr98S1q8PA+Chh+ry/vv3UqZMQS9H5jssKRhjcoTDh8MJDp5BbGwCN91UiGnT2tO5cy1vh+VzLCkYY3KEypWL8+CDdQgMDOCdd9pSrFigt0PySR69OFdE2onIfhEJFZGXUni9goisFpHtIrJLRKwR3BjjlqioOEaMWMmmTcdd6z7+uDOzZnWyhHAdPJYURMQfmArcC9QBHhaROsmKjQS+VNWGQA9gmqfiMcbkHD///AfBwTMYN24dAwZ8Q2Kiow/O399uQrtenvwEmwChqnpIVWOBecD9ycoocPn6sKLAnx6Mxxjj4y5ciOGpp76jefO5/P77GerUKc306R3snoNM5Mk+hXLAsSTLYcCtycq8CqwQkaeBgkDrlDYkIgOAAQAVKlTI9EA9yu47MCZTLF16gIEDv+XYsQsEBPjx8st38PLLd5Ivn3WNZiZP1hRSSt3Jr7N8GJirquWB+4D/iMhVManqTFUNUdWQ0qVLeyBUD7qWhGD3FxhzhfPno+nZcyHHjl0gJKQsW7cOYMyYuy0heIAnP9EwIOkdI+W5unmoH9AOQFXXi0ggUAo46cG4vMPuOzAmQ1QVVfDzE4oWDWTy5Hb8/Xckzzxzmw1g50Ge/GQ3A9VFpLKI5MXRkbwkWZmjQCsAEakNBAKnPBiTMcYH/PlnBF26zGfChPWudb16NWD4cBvR1NM89umqajwwGFgO7MNxldEeEXlNRDo5iz0H9BeRncAXQB9VtVNqY3IpVWX27G3UqTOVxYv38/bb/yMqKs7bYeUqHm2QU9WlwNJk6/4vyfO9QDNPxmCM8Q2HDoXTv/83rFp1GID27aszfXoH8ufP4+XIchfrpTHGeFVCQiKTJ2/klVdWERUVT6lSBZg8uR09egQhYpeaZjVLCsYYr1uwYB9RUfE8/HAQkya1o3RpG8DOWywpGGOyXGxsAhERMZQsWQB/fz9mz+7EgQNn6NixprdDy/WsG98Yk6U2bz5OSMhMevVaxOXrSmrVKmUJIZuwmoIxJktcuhTH6NGree+9DSQmKpcuxXHyZCQ33FDI26GZJCwpGGM8bs2aI/Tv/w2hoWfx8xOGD2/KmDF3U6CAXVmU3VhSMMZ4jKoyZMgypkzZDEC9emWYPbsTjRuX83JkJjWWFIwxHiMiFCmSjzx5/Bg5sjkvvXQHefP6ezsskwZLCsaYTHX69CUOHjzLrbeWB2DUqLvo2bM+der42GCWuZRbVx+JSF4RqebpYIwxvktVmTfvV2rXnkrnzvMJD48CIDAwwBKCD0k3KYhIe2A38INzOVhEFnk6MGOM7wgLu8D998/j4Ye/4vTpS9SpU5pLl2zMIl/kTvPRazgmx1kNoKo7rNZgjAFITFRmzdrG88//wIULMRQpko93321Lv34NbYgKH+VOUohT1XPJ/oNtJFNjDP36LWHu3B0AdOpUk2nT7qNcuSLpvMtkZ+70KewTkYcAP+fcCBOBDR6OyxjjAx59tB5lyhRk3ryufP11d0sIOYA7SWEw0AhIBBYC0cBQTwZljMmefv31JJMm/XNO2KpVFQ4dGkL37jaiaU7hTvPRPar6IvDi5RUi8gCOBGGMyQViYuJ5881feOONn4mLSyQkpCzNmlUAoGDBvF6OzmQmd2oKI1NY90pmB2KMyZ42bgyjUaOZjBnzE3FxiQwaFEK9ejd4OyzjIanWFETkHqAdUE5E3kvyUhEcTUnGmBwsMjKWUaNWM3HiBlShevUSzJrViebNK3o7NONBaTUfnQR+xdGHsCfJ+gjgJU8GZYzxvldeWcWkSRvx8xOef74pr77awqbGzAVSTQqquh3YLiKfqWp0FsZkjMkGXnnlTnbvPslbb7UmJKSst8MxWcSdPoVyIjJPRHaJyO+XHx6PzBiTpZYs2c99931GXFwCAKVLF+THH3tbQshl3EkKc4GPAAHuBb4E5nkwJmNMFjp5MpIePRZw//3zWLYslI8/3untkIwXuZMUCqjqcgBVPaiqI4G7PRuWMcbTVJVPP91F7dpTmT9/DwUK5GHSpHb07Rvs7dCMF7lzn0KMOO5KOSgiA4HjQBnPhmWM8aSjR88zcOC3LFsWCkDr1lWYObMDlSsX93JkxtvcSQrDgELAEODfQFHgX54MyhjjWStWHGTZslCKFQvkvffa0qdPsN2RbAA3koKqbnQ+jQB6AYhIeU8GZYzJfJGRsa67j/v1a8jx4xcYMKARN91U2MuRmewkzT4FEWksIp1FpJRzua6IfIINiGeMz4iPT2T8+HVUrDiRQ4fCAcc0maNHt7CEYK6SalIQkTeBz4CewPci8gqOORV2AjWyJjxjzPXYufMEt946ixdfXMmZM1F8/fVv3g7JZHNpNR/dDzRQ1SgRKQH86VzenzWhGWOuVUxMPGPHrmXcuHXExydSoUJRZs7swD332PxYJm1pJYVoVY0CUNWzIvKbJQRjsr/t2/+iZ8+F7Nt3GhEYPLgxb7zRisKF83k7NOMD0koKVUTk8vDYAlRKsoyqPpDexkWkHTAJ8Admqeq4FMo8BLyKYza3nar6iPvhe9DC9nB4qbejMCbD8uUL4ODBcGrWLMmsWZ24444K3g7J+JC0kkLXZMtTMrJhEfEHpgJtgDBgs4gsUdW9ScpUB0YAzVQ1XESyz/0PmZkQKt+XedsyJgXbtv1Fw4Y3IiLUqVOaZct6cvvtNxMY6M5V58b8I60B8X68zm03AUJV9RCAiMzD0U+xN0mZ/sBUVQ137vPkde4z8z1n01Gb7Cs8PIrhw1cwZ84OvviiKz16BAHQsmVlL0dmfJUnTyPKAceSLIcBtyYrUwNARNbhaGJ6VVW/T74hERkADACoUMGqwsYALFq0jyefXMqJExfJl8+fM2cueTskkwN4MimkdHtk8tPuAKA60AIoD/wsIkGqeu6KN6nOBGYChISEZO6pu/UdGB9z4sRFnn56GQsWOCrdzZrdzKxZnahVq5SXIzM5gdtJQUTyqWpMBrYdBtycZLk8jstak5fZoKpxwGER2Y8jSWzOwH6uT1oJwfoCTDazdeuftGnzH8LDoylYMA/jxrXmyScb4+dnQ1SYzJFuUhCRJsBsHGMeVRCRBsDjqvp0Om/dDFQXkco4BtHrASS/suhr4GFgrvOu6RrAoYwdQiaxvgPjA+rUKU3p0gVp0qQcM2Z0oGLFYt4OyeQw7gydPRnoAJwBUNWduDF0tqrGA4OB5cA+4EtV3SMir4lIJ2ex5cAZEdmL427p51X1TMYPw5icKTFRmTlzK+fOOSY/zJ8/D2vX9mHZsp6WEIxHuNN85KeqfyQbQTHBnY2r6lJgabJ1/5fkuQLPOh/GmCT27z/N449/wy+/HGXz5uN8+KHjXOqGGwp5OTKTk7mTFI45m5DUee/B04BNx2mMh8TFJfDuu+t59dU1xMQkcOONhbj33ureDsvkEu4khUE4mpAqAH8DK53rjDGZbPv2v+jXbwnbt58AoG/fYN59ty3Fi+f3cmQmt3AnKcSrag+PR2JMLnfw4FmaNJlFfHwilSoVY+bMDrRpU9XbYZlcxp2ksNl5qeh8YKGqRng4JmNypapVS9CrV30KF87Lv//dikKF8no7JJMLpXv1kapWBcYCjYDdIvK1iFjNwZjrdPFiLEOGLGP9+n9u/J89uxOTJt1rCcF4jTuXpKKq/1PVIcAtwAUck+8YY67R8uWh1K07jfff38TAgd/huBAPmyfZeJ07N68VwjGQXQ+gNrAYuN3DcRmTI509G8WwYcv55JOdADRqdBOzZ3eyZGCyDXf6FH4FvgHGq+rPHo7HmBxrwYK9PPXUUk6ejCQwMIAxY1rw7LNNCQhwq8JuTJZwJylUUdVEj0diTA527lw0AwZ8Q3h4NM2bV+TDDztSo0ZJb4dlzFVSTQoi8q6qPgd8JSJXDQzkzsxrxuRmqkpiouLv70exYoFMm9ae8PAonngixAawM9lWWjWF+c5/MzTjmjEGjhw5x4AB39CyZWVeeukOANcEOMZkZ2nNvLbJ+bS2ql6RGERkMHC9M7NlLZs3wWSBhIREpk7dzMsv/0hkZBx7957imWdus2kxjc9wp4frXyms65fZgXiczZtgPGzfvlM0bz6XoUO/JzIyjh49gti27QlLCManpNWn0B3HZaiVRWRhkpcKA+dSfpcPsHkTTCaLj0/krbd+4bXX1hIbm0DZsoX54IP2dOpU09uhGZNhaZ3CbMIxh0J5YGqS9RHAdk8GZYwv8fMTVqw4RGxsAv3738L48W0oVizQ22EZc03S6lM4DBzGMSqqMSaJqKg4IiJiKVOmIH5+wqxZHTl27AItW1b2dmjGXJdU+xRE5Cfnv+EicjbJI1xEzmZdiMZkL2vX/kGDBtN59NGFruEpqlcvaQnB5AhpNR9dnnKzVFYEYkx2d+FCDCNGrGTatC0A5Mnjz+nTlyhduqCXIzMm86RaU0hyF/PNgL+qJgBNgScA+yswucqyZQcICprGtGlbCAjwY/Tou9i2bYAlBJPjuHOt3NdAYxGpCnwCfAd8DnTwZGDGZAeqSv/+3zB7tuPaipCQssyZ04l69W7wcmTGeIY79ykkqmoc8AAwUVWfBsp5NixjsgcRoXz5IgQGBvDOO21Yv76fJQSTo7k1HaeIPAj0Ajo71+XxXEjGeNeff0Zw8OBZ7ryzIgAvv3wnvXrVp2rVEl6OzBjPc/eO5rtxDJ19SEQqA194Nixjsp6qMnv2NurUmUrXrl9y5swlAPLm9beEYHKNdGsKqvqriAwBqolILSBUVf/t+dCMyTqHDoXTv/83rFp1GIAOHWoQF2cjxpvcx52Z1+4E/gMcBwS4UUR6qeo6TwdnjKclJCQyefJGRo5czaVLcZQqVYDJk9vRo0eQzYZmciV3+hQmAPep6l4AEamNI0mEeDIwY7JC795f8/nnuwF45JF6TJx4j11manI1d/oU8l5OCACqug/I67mQjMk6/fvfQvnyRViypAefffaAJQST67lTU9gmIjNw1A4AemID4hkftXnzcVatOsyLLzomvmnRohKhoU+TL58Nb20MuJcUBgJDgBdw9CmsBd73ZFDGZLZLl+IYPXo17723gcRE5fbbb3ZdcmoJwZh/pPnXICL1gKrAIlUdnzUhGZO51qw5wuOPL+HgwXD8/IThw5vSqFFZb4dlTLaU1iQ7L+OYYW0bjmEuXlPVOVkWmTHX6fz5aF544QdmztwGQL16ZZg9uxONG9sN+cakJq2O5p5AfVV9EGgMDMroxkWknYjsF5FQEXkpjXLdRERFxK5oMplm1KjVzJy5jTx5/HjttRZs2TLAEoIx6Uir+ShGVSMBVPWUiLhzpZKLiPjjmLGtDRAGbBaRJUmvZHKWK4yjz2JjhiI3JgWq6rq/4P/+7y4OHz7HuHGtqFu3jJcjM8Y3pPVDX0VEFjofi4CqSZYXpvG+y5rguPv5kKrGAvOA+1Mo9zowHojOcPTGOKkqn3++m5YtPyE2NgGAUqUK8M03D1tCMCYD0qopdE22PCWD2y4HHEuyHAbcmrSAiDQEblbVb0VkeGobEpEBwACAChUqZDAMk9OFhV1g0KDv+Pbb3wH47LNd9O3b0MtRGeOb0pqj+cfr3HZKYwSo60VHc9QEoE96G1LVmcBMgJCQEE2nuMklEhOVDz/cyvPP/0BERCxFi+bj3Xfb0qdPsLdDM8ZnefIC7TAcs7ZdVh74M8lyYSAIWONsA74RWCIinVR1iwfjMjlAaOhZ+vf/hjVrjgBw//01mTatPWXLFvZuYMb4OE8mhc1AdedQ28eBHsAjl19U1fMkmf9ZRNYAwy0hGHf8/PMfrFlzhDJlCjJlyr1061bHBrAzJhO4nRREJJ+qxrhbXlXjRWQwsBzwB+ao6h4ReQ3YoqpLMh6uyc3OnYumWLFAAPr0CebUqUv069eQkiULeDkyY3KOdC8zFZEmIrIbOOBcbiAibg1zoapLVbWGqla9PAeDqv5fSglBVVtYLcGkJCYmntGjV1Ox4kQOHDgDOKbJfOGFZpYQjMlk7tQUJgMdgK8BVHWniNzt0aiMcdqwIYx+/Zawd+8pAJYvP0j16iW9HJUxOZc7ScFPVf9I1l6b4KF4jAEgMjKWUaNWM3HiBlShevUSzJ7dyTWInTHGM9xJCsdEpAmgzruUnwZ+92xYJjfbuDGMRx5ZyKFD4fj7C8OH387o0XeRP38eb4dmTI7nTlIYhKMJqQLwN7CSaxgHyRh3FSsWyPHjF2jQ4AZmz+5kI5oak4XSTQqqehLH5aTGeMwvvxylWbObERFq1izFqlWP0bhxWfLk8fd2aMbkKukmBRH5kCR3Il+mqgM8EpHJVU6ejGTIkGXMn7+Hjz/uTO/eDQC4/fab03mnMcYT3Gk+WpnkeSDQhSvHNDImw1SVzz7bzdCh33P2bBQFCuRxDWRnjPEed5qP5iddFpH/AD94LCKT4x09ep6BA79l2bJQANq0qcLMmR2pVKmYlyMzxlzLMBeVAbsu0FyTjRvDaN36P1y8GEuxYoFMmHAPjz3WwIaoMCabcKdPIZx/+hT8gLNAqrOoGZOW4OAbufnmItSqVYqpU+/jpptsADtjspM0k4I4Tt8a4BjQDiBRVW3oauO2+PhEpkzZRO/eDShRIj/58gWwbt2/KF48v7dDM8akIM2xj5wJYJGqJjgflhCM23buPMGtt85i2LDlPPvsctd6SwjGZF/uzLu8SURu8XgkJseIjo5n5MhVhIR8yLZtf1GhQlEefjjI22EZY9yQavORiASoajxwB9BfRA4CkThmVFNVtURhrvK//x2jX78l/PbbaURg8ODGvPFGKwoXzuft0IwxbkirT2ETcAvQOYtiMT4uNPQsd975EYmJSs2aJZk9uxPNmtmc2sb4krSSggCo6sEsisX4uGrVSjBgwC2UKJGfUaPuIjDQkxP7GWM8Ia2/2tIi8mxqL6rqex6Ix/iQ8PAonntuBX37BruGtJ42rb3dc2CMD0srKfgDhXDWGIxJauHCfTz11FJOnLjI1q1/sWPHE4iIJQRjfFxaSeEvVX0tyyIxPuHEiYsMHryUr77aB8Add1Rg1qyOlgyMySHS7VMwBhwD2H3yyU6GDVtOeHg0hQrl5a23WjNwYAh+fvZVMSanSCsptMqyKEy2d+5cNM89t4Lw8GjatavG9OntqVjRBrAzJqdJNSmo6tmsDMRkP4mJSmKiEhDgR/Hi+ZkxowOXLsXx6KP1rbnImBzKnTuaTS7022+nad78I8aN+8W1rmvXOvTqZSOaGpOTWVIwV4iLS+CNN36mQYPprFt3jNmztxMdHe/tsIwxWcTuLjIu27f/xb/+tYQdO04A0K9fQ95+u43dhGZMLmJ/7Ya4uARGj17D+PHrSEhQKlUqxocfdqR16yreDs0Yk8UsKRgCAvzYuPE4iYnK0KG3MnZsSwoVyuvtsIwxXmBJIZeKiIghIiKWsmULIyLMmtWREycu0rTpzd4OzRjjRdbRnAstXx5KUNAH9Oy5kMvzJlWuXNwSgjHGkkJucubMJR577GvatfuMo0fPExERw5kzUd4OyxiTjXg0KYhIOxHZLyKhIvJSCq8/KyJ7RWSXiPwoIhU9GU9upaosWLCXOnWm8cknOwkMDGD8+NZs2PA4pUoV8HZ4xphsxGN9CiLiD0wF2gBhwGYRWaKqe5MU2w6EqOolERkEjAe6eyqm3EhV6dlzIV988SsAzZtX5MMPO1KjRkkvR2aMyY48WVNoAoSq6iFVjQXmAfcnLaBaxhJqAAAXTklEQVSqq1X1knNxA1Deg/HkSiJCnTqlKVw4Lx980J7Vqx+zhGCMSZUnrz4qBxxLshwG3JpG+X7AspReEJEBwACAChVsesf0HD4czqFD4bRq5bjP4MUXm9GnTzDlyxfxcmTGmOzOkzWFlAbI0RQLijwKhABvp/S6qs5U1RBVDSldunQmhpizJCQkMmnSBoKCPqB79wWcPBkJQJ48/pYQjDFu8WRNIQxIeo1jeeDP5IVEpDXwCnCXqsZ4MJ4cbe/eUzz++BLWrw8DoFOnmjbPgTEmwzyZFDYD1UWkMnAc6AE8krSAiDQEZgDtVPWkB2PJseLiEnjrrXW8/vpaYmMTKFu2MB980J5OnWp6OzRjjA/yWFJQ1XgRGQwsxzHf8xxV3SMirwFbVHUJjuaiQsB/ncMxH1XVTp6KKSd65JGFLFjguKCrf/9bePvtNhQtGujlqIwxvsqjw1yo6lJgabJ1/5fkeWtP7j83GDr0VnbsOMGMGR1o2bKyt8Mxxvg4u6PZx/z00xHGjFnjWr7jjgrs2/eUJQRjTKawAfF8xIULMbz44g9Mn74VgLvvrkzz5o4bwAMCLLcbYzKHJQUfsHTpAZ544lvCwi6QJ48fr7xyJ7fdZvf5GWMynyWFbOz06Us888z3fPbZbgCaNCnH7NmdCAoq4+XIjDE5lSWFbOy1137is892kz9/AGPHtmTo0Fvx97emImOM51hSyGZUFefluYwZ04K//47kjTdaUrVqCS9HZozJDey0M5tQVT78cCu33z6H6Oh4AIoXz8/8+d0sIRhjsowlhWzg4MGztGr1CQMGfMuGDWF8+eUeb4dkjMmlrPnIixwD2G1k5MhVREXFU7p0Ad5//14eeqiut0MzxuRSlhS8ZM+ek/zrX0vYtOk4AD171mPixHY2E5oxxqssKXjJ9u0n2LTpOOXKFWbGjA60b1/D2yEZY4wlhax06lQkpUsXBBw1g3PnounVq74NYGeMyTasozkLXLoUx/DhK6hUaRL79p0CHNNkDh7cxBKCMSZbsZqCh61efZj+/b/h4MFw/PyEtWv/oHZtmz3OGJM9WVLwkPPno3nhhR+YOXMbAPXqlWHOnPsJCSnr5ciMMSZ1lhQ84JdfjtKjxwKOH48gTx4/Ro1qzosv3kHevP7eDs0YY9JkScEDbryxEGfORHHbbeWZNasjdevaAHbGGN9gSSETqCo//HCINm2qICJUq1aCX37pS3DwjTaAnTHGp9gv1nU6duw8HTt+wT33fMpHH+1wrW/UqKwlBGOMz7GawjVKTHQMYPf88z8QERFL0aL5yJfP+gyMMb7NksI1OHDgDP37f8NPP/0BQOfOtZg69T7Kli3s5ciMMeb6WFLIoP/97xitWn1CdHQ8ZcoUZMqUe+nWrY5rDgST+8TFxREWFkZ0dLS3QzGGwMBAypcvT548ea7p/ZYUMigkpCzVq5egYcObeO+9tpQsaQPY5XZhYWEULlyYSpUq2cmB8SpV5cyZM4SFhVG5cuVr2ob1hKYjJiaef/97LadPXwIgb15/1q37Fx9/3NkSggEgOjqakiVLWkIwXicilCxZ8rpqrVZTSMOGDWH067eEvXtPsW/faT799AEAChfO5+XITHZjCcFkF9f7XbSkkILIyFhGjlzFpEkbUYUaNUryxBONvB2WMcZ4nDUfJfPjj4eoV+8DJk7ciJ+f8NJLzdi5cyB33lnR26EZkyp/f3+Cg4MJCgqiY8eOnDt3zvXanj17aNmyJTVq1KB69eq8/vrrqKrr9WXLlhESEkLt2rWpVasWw4cP98YhpGn79u08/vjj3g4jTW+++SbVqlWjZs2aLF++PMUyq1at4pZbbiEoKIjHHnuM+HjHfOyLFy+mfv36BAcHExISwi+//ALAjh07aNq0KXXr1qV+/frMnz/fta0ePXpw4MCBzD8QVfWpR6NGjfSavIPjkYb9+0+ryKsKr2pw8HTduvXPa9uXyVX27t3r7RC0YMGCrue9e/fWsWPHqqrqpUuXtEqVKrp8+XJVVY2MjNR27drplClTVFV19+7dWqVKFd23b5+qqsbFxenUqVMzNba4uLjr3ka3bt10x44dWbrPjNizZ4/Wr19fo6Oj9dChQ1qlShWNj4+/okxCQoKWL19e9+/fr6qqo0aN0lmzZqmqakREhCYmJqqq6s6dO7VmzZqqqrp//379/fffVVX1+PHjeuONN2p4eLiqqq5Zs0Yff/zxFONJ6TsJbFE3fmOt+SiJGjVKMnTorZQuXZDnn7+dPHnsZjSTQe96qG/hOU2/jFPTpk3ZtWsXAJ9//jnNmjWjbdu2ABQoUIApU6bQokULnnrqKcaPH88rr7xCrVq1AAgICODJJ5+8apsXL17k6aefZsuWLYgIo0ePpmvXrhQqVIiLFy8CsGDBAr799lvmzp1Lnz59KFGiBNu3byc4OJhFixaxY8cOihUrBkC1atVYt24dfn5+DBw4kKNHjwIwceJEmjVrdsW+IyIi2LVrFw0aNABg06ZNPPPMM0RFRZE/f34++ugjatasydy5c/nuu++Ijo4mMjKSVatW8fbbb/Pll18SExNDly5dGDNmDACdO3fm2LFjREdHM3ToUAYMGOD255uSxYsX06NHD/Lly0flypWpVq0amzZtomnTpq4yZ86cIV++fNSo4ZhlsU2bNrz55pv069ePQoUKucpFRka6+gUulwUoW7YsZcqU4dSpUxQrVow777yTPn36EB8fT0BA5v2U5+qk8PffFxky5HsGDmzE3Xc7Lt+aMKGdl6My5tolJCTw448/0q9fP8DRdNSo0ZX9YVWrVuXixYtcuHCBX3/9leeeey7d7b7++usULVqU3bt3AxAeHp7ue37//XdWrlyJv78/iYmJLFq0iL59+7Jx40YqVarEDTfcwCOPPMKwYcO44447OHr0KPfccw/79u27YjtbtmwhKCjItVyrVi3Wrl1LQEAAK1eu5OWXX+arr74CYP369ezatYsSJUqwYsUKDhw4wKZNm1BVOnXqxNq1a2nevDlz5syhRIkSREVF0bhxY7p27UrJkiWv2O+wYcNYvXr1VcfVo0cPXnrppSvWHT9+nNtuu821XL58eY4fP35FmVKlShEXF8eWLVsICQlhwYIFHDt2zPX6okWLGDFiBCdPnuS77767ar+bNm0iNjaWqlWrAuDn50e1atXYuXPnVf/H1yNXJgVV5dNPd/HMM8s5ezaK/ftPs337E3YFibl+GTijz0xRUVEEBwdz5MgRGjVqRJs2bQDHdz2173VGvu8rV65k3rx5ruXixYun+54HH3wQf39Hbbt79+689tpr9O3bl3nz5tG9e3fXdvfu3et6z4ULF4iIiKBw4X9GB/jrr78oXfqfianOnz/PY489xoEDBxAR4uLiXK+1adOGEiVKALBixQpWrFhBw4YNAUdt58CBAzRv3pzJkyezaNEiAI4dO8aBAweuSgoTJkxw78OBK/poLkv++YoI8+bNY9iwYcTExNC2bdsrzvC7dOlCly5dWLt2LaNGjWLlypVXfAa9evXi448/xs/vn67gMmXK8Oeff/pOUhCRdsAkwB+Yparjkr2eD/gEaAScAbqr6hFPxnT06HkGDvyWZctCAWjbtiozZnSwhGB8Wv78+dmxYwfnz5+nQ4cOTJ06lSFDhlC3bl3Wrl17RdlDhw5RqFAhChcuTN26ddm6dauraSY1qSWXpOuSXxtfsGBB1/OmTZsSGhrKqVOn+Prrrxk5ciQAiYmJrF+/nvz586d5bEm3PWrUKO6++24WLVrEkSNHaNGiRYr7VFVGjBjBE088ccX21qxZw8qVK1m/fj0FChSgRYsWKV7Xn5GaQvny5a846w8LC6Ns2asn1GratCk///wz4Ehav//++1VlmjdvzsGDBzl9+jSlSpXiwoULtG/fnrFjx15RGwHHZ57WZ3ctPHb1kYj4A1OBe4E6wMMiUidZsX5AuKpWAyYAb3kqnsREYdq6xtStO41ly0IpXjyQuXPv5/vve1KpUjFP7daYLFW0aFEmT57MO++8Q1xcHD179uSXX35xnXVGRUUxZMgQXnjhBQCef/553njjDdePU2JiIu+9995V223bti1TpkxxLV9uPrrhhhvYt2+fq3koNSJCly5dePbZZ6ldu7brrDz5dnfs2HHVe2vXrk1oaKhr+fz585QrVw6AuXPnprrPe+65hzlz5rj6PI4fP87Jkyc5f/48xYsXp0CBAvz2229s2LAhxfdPmDCBHTt2XPVInhAAOnXqxLx584iJieHw4cMcOHCAJk2aXFXu5MmTAMTExPDWW28xcOBAAEJDQ121jW3bthEbG0vJkiWJjY2lS5cu9O7dmwcffPCq7f3+++/UrVs31c/gWnjyktQmQKiqHlLVWGAecH+yMvcDHzufLwBaiYdO2c9H52PMD3dx8WIsXbvWZu/ep3jssWCrIZgcp2HDhjRo0IB58+aRP39+Fi9ezNixY6lZsyb16tWjcePGDB48GID69eszceJEHn74YWrXrk1QUBB//fXXVdscOXIk4eHhBAUF0aBBA9cZ9Lhx4+jQoQMtW7bkpptuSjOu7t278+mnn7qajgAmT57Mli1bqF+/PnXq1GH69OlXva9WrVqcP3+eiIgIAF544QVGjBhBs2bNSEhISHV/bdu25ZFHHqFp06bUq1ePbt26ERERQbt27YiPj6d+/fqMGjXqqrPva1G3bl0eeugh6tSpQ7t27Zg6daqr6ey+++7jzz//BODtt9+mdu3a1K9fn44dO9KyZUsAvvrqK4KCgggODuapp55i/vz5iAhffvkla9euZe7cuQQHBxMcHOxKnH///Tf58+dP93PPKEmpLSxTNizSDWinqo87l3sBt6rq4CRlfnWWCXMuH3SWOZ1sWwOAAQAVKlRo9Mcff2Q8oHeFb/bUILb9Irp2TV5hMeba7du3j9q1a3s7jBxtwoQJFC5cONvfq5CVJkyYQJEiRVwXFSSV0ndSRLaqakh62/Vkn0JKp+DJM5A7ZVDVmcBMgJCQkGvLYs8pHa/pjcYYbxs0aBD//e9/vR1GtlKsWDF69eqV6dv1ZPNRGHBzkuXywJ+plRGRAKAocNaDMRljfFBgYKBHfgB9Wd++fTP1/oTLPJkUNgPVRaSyiOQFegBLkpVZAjzmfN4NWKWeas8yxoPsa2uyi+v9LnosKahqPDAYWA7sA75U1T0i8pqIdHIWmw2UFJFQ4Fng6m59Y7K5wMBAzpw5Y4nBeJ0651MIDAy85m14rKPZU0JCQnTLli3eDsMYF5t5zWQnqc28lh06mo3JFfLkyXPNs1wZk93Y0NnGGGNcLCkYY4xxsaRgjDHGxec6mkXkFHANtzQDUAo4nW6pnMWOOXewY84drueYK6pq6fQK+VxSuB4issWd3vecxI45d7Bjzh2y4pit+cgYY4yLJQVjjDEuuS0pzPR2AF5gx5w72DHnDh4/5lzVp2CMMSZtua2mYIwxJg2WFIwxxrjkyKQgIu1EZL+IhIrIVSOvikg+EZnvfH2jiFTK+igzlxvH/KyI7BWRXSLyo4hU9EacmSm9Y05SrpuIqIj4/OWL7hyziDzk/L/eIyKfZ3WMmc2N73YFEVktItud3+/7vBFnZhGROSJy0jkzZUqvi4hMdn4eu0TklkwNQFVz1APwBw4CVYC8wE6gTrIyTwLTnc97APO9HXcWHPPdQAHn80G54Zid5QoDa4ENQIi3486C/+fqwHaguHO5jLfjzoJjngkMcj6vAxzxdtzXeczNgVuAX1N5/T5gGY6ZK28DNmbm/nNiTaEJEKqqh1Q1FpgH3J+szP3Ax87nC4BWIpLS1KC+It1jVtXVqnrJubgBx0x4vsyd/2eA14HxQE4Y19qdY+4PTFXVcABVPZnFMWY2d45ZgSLO50W5eoZHn6Kqa0l7Bsr7gU/UYQNQTERuyqz958SkUA44lmQ5zLkuxTLqmAzoPFAyS6LzDHeOOal+OM40fFm6xywiDYGbVfXbrAzMg9z5f64B1BCRdSKyQUTaZVl0nuHOMb8KPCoiYcBS4OmsCc1rMvr3niE5cT6FlM74k193604ZX+L28YjIo0AIcJdHI/K8NI9ZRPyACUCfrAooC7jz/xyAowmpBY7a4M8iEqSq5zwcm6e4c8wPA3NV9V0RaQr8x3nMiZ4Pzys8+vuVE2sKYcDNSZbLc3V10lVGRAJwVDnTqq5ld+4cMyLSGngF6KSqMVkUm6ekd8yFgSBgjYgcwdH2usTHO5vd/W4vVtU4VT0M7MeRJHyVO8fcD/gSQFXXA4E4Bo7Lqdz6e79WOTEpbAaqi0hlEcmLoyN5SbIyS4DHnM+7AavU2YPjo9I9ZmdTygwcCcHX25khnWNW1fOqWkpVK6lqJRz9KJ1U1ZfncnXnu/01josKEJFSOJqTDmVplJnLnWM+CrQCEJHaOJLCqSyNMmstAXo7r0K6DTivqn9l1sZzXPORqsaLyGBgOY4rF+ao6h4ReQ3YoqpLgNk4qpihOGoIPbwX8fVz85jfBgoB/3X2qR9V1U5eC/o6uXnMOYqbx7wcaCsie4EE4HlVPeO9qK+Pm8f8HPChiAzD0YzSx5dP8kTkCxzNf6Wc/SSjgTwAqjodR7/JfUAocAnom6n79+HPzhhjTCbLic1HxhhjrpElBWOMMS6WFIwxxrhYUjDGGONiScEYY4yLJQWT7YhIgojsSPKolEbZSqmNJpnBfa5xjsS50zlERM1r2MZAEentfN5HRMomeW2WiNTJ5Dg3i0iwG+95RkQKXO++Te5gScFkR1GqGpzkcSSL9ttTVRvgGCzx7Yy+WVWnq+onzsU+QNkkrz2uqnszJcp/4pyGe3E+A1hSMG6xpGB8grNG8LOIbHM+bk+hTF0R2eSsXewSkerO9Y8mWT9DRPzT2d1aoJrzva2c4/Tvdo5zn8+5fpz8Mz/FO851r4rIcBHphmN8qc+c+8zvPMMPEZFBIjI+Scx9ROT9a4xzPUkGQhORD0RkizjmURjjXDcER3JaLSKrnevaish65+f4XxEplM5+TC5iScFkR/mTNB0tcq47CbRR1VuA7sDkFN43EJikqsE4fpTDnMMedAeaOdcnAD3T2X9HYLeIBAJzge6qWg/HCACDRKQE0AWoq6r1gbFJ36yqC4AtOM7og1U1KsnLC4AHkix3B+ZfY5ztcAxrcdkrqhoC1AfuEpH6qjoZx7g4d6vq3c6hL0YCrZ2f5Rbg2XT2Y3KRHDfMhckRopw/jEnlAaY429ATcIzpk9x64BURKQ8sVNUDItIKaARsdg7vkR9HgknJZyISBRzBMfxyTeCwqv7ufP1j4ClgCo75GWaJyHeA20Nzq+opETnkHLPmgHMf65zbzUicBXEM+5B01q2HRGQAjr/rm3BMOLMr2Xtvc65f59xPXhyfmzGAJQXjO4YBfwMNcNRwr5o0R1U/F5GNQHtguYg8jmOY4Y9VdYQb++iZdMA8EUlxjg3neDxNcAzC1gMYDLTMwLHMBx4CfgMWqaqK4xfa7ThxzEA2DpgKPCAilYHhQGNVDReRuTgGhktOgB9U9eEMxGtyEWs+Mr6iKPCXc4z8XjjOkq8gIlWAQ84mkyU4mlF+BLqJSBlnmRLi/vzUvwGVRKSac7kX8JOzDb6oqi7F0Ymb0hVAETiG707JQqAzjnkA5jvXZShOVY3D0Qx0m7PpqQgQCZwXkRuAe1OJZQPQ7PIxiUgBEUmp1mVyKUsKxldMAx4TkQ04mo4iUyjTHfhVRHYAtXBMWbgXx4/nChHZBfyAo2klXaoajWMEyv+KyG4gEZiO4wf2W+f2fsJRi0luLjD9ckdzsu2GA3uBiqq6ybkuw3E6+yreBYar6k4cczPvAebgaJK6bCawTERWq+opHFdGfeHczwYcn5UxgI2SaowxJgmrKRhjjHGxpGCMMcbFkoIxxhgXSwrGGGNcLCkYY4xxsaRgjDHGxZKCMcYYl/8HfqKPQJpq6cUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, score = roc_curve(y_true = testdf['y'], y_score = phat2)\n",
    "auc = roc_auc_score(y_true = testdf['y'], y_score = phat2)\n",
    "plot_roc(fpr, tpr, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) (1 pt) Comment on how the sensitivity and specificity compare between the 'naive' values computed from the training data, and the unbiased values computed using the test data. Are the results similar or is one of the results more optimistic than the other.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the result based on training data, the result based on test data has higher sensitivity and specificity. Thus, the result with test data is more optimistic but the results are similar. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
